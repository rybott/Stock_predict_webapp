{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with just 2023 for my laptop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<duckdb.duckdb.DuckDBPyConnection object at 0x000001CDD794E770>\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "con = duckdb.connect(r\"C:\\Users\\rybot\\OneDrive\\Databases\\datadump.duckdb\")\n",
    "print(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Stocks',)]\n"
     ]
    }
   ],
   "source": [
    "tables = con.execute('PRAGMA show_tables;').fetchall()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Datetime        open        high         low       close  volume  \\\n",
      "0 2023-01-03 04:00:00  129.391006  130.113998  129.386002  130.110001  5381.0   \n",
      "1 2023-01-03 04:01:00  129.977005  130.283005  129.972000  130.209000  6072.0   \n",
      "2 2023-01-03 04:02:00  130.285004  130.352005  130.270004  130.279007  1053.0   \n",
      "3 2023-01-03 04:03:00  130.294998  130.401993  130.289993  130.388000  1754.0   \n",
      "4 2023-01-03 04:04:00  130.384003  130.570999  130.378998  130.567001  3766.0   \n",
      "\n",
      "  Stock  interval  \n",
      "0  AAPL       1.0  \n",
      "1  AAPL       1.0  \n",
      "2  AAPL       1.0  \n",
      "3  AAPL       1.0  \n",
      "4  AAPL       1.0  \n"
     ]
    }
   ],
   "source": [
    "qry = '''\n",
    "    SELECT * FROM Stocks\n",
    "    WHERE EXTRACT(YEAR FROM Datetime) = 2023 \n",
    "    AND Stock = 'AAPL' \n",
    "    AND Interval = 1\n",
    "'''\n",
    "\n",
    "df = con.execute(qry).fetchdf()\n",
    "# Sort the Data from oldest to newest\n",
    "df = df.sort_values(by='Datetime').reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Flattening the Data for:\n",
    "#### Packet Size (Only 1 min intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data, and calculating P/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Datetime        open        high         low       close  \\\n",
      "235 2023-01-03 09:01:00  130.037003  130.113998  129.942001  129.960999   \n",
      "236 2023-01-03 09:02:00  129.936996  129.964996  129.882996  129.921005   \n",
      "237 2023-01-03 09:03:00  129.917007  129.964996  129.882996  129.910995   \n",
      "238 2023-01-03 09:04:00  129.897995  129.934998  129.873001  129.882004   \n",
      "239 2023-01-03 09:05:00  129.927002  129.964996  129.875000  129.884003   \n",
      "\n",
      "      volume Stock  interval      Time  \n",
      "235  14208.0  AAPL       1.0  09:01:00  \n",
      "236   3281.0  AAPL       1.0  09:02:00  \n",
      "237   3530.0  AAPL       1.0  09:03:00  \n",
      "238   5429.0  AAPL       1.0  09:04:00  \n",
      "239   1600.0  AAPL       1.0  09:05:00  \n"
     ]
    }
   ],
   "source": [
    "df['Time'] = df['Datetime'].dt.time\n",
    "start_time = pd.to_datetime('09:00:00').time()\n",
    "end_time = pd.to_datetime('16:00:00').time()\n",
    "TradingDay_df = df[(df['Time']>start_time)&(df['Time']<end_time)]\n",
    "print(TradingDay_df.head())\n",
    "\n",
    "def trail_stoploss(index, tradingdata, whole_percentage):\n",
    "    idx = index\n",
    "    td = tradingdata\n",
    "    pct = whole_percentage/100\n",
    "    max_holdtime = 30 # Only hold the trade for twenty minutes\n",
    "\n",
    "    after_td = td.loc[idx:idx+max_holdtime+1] # Get the dataframe from the row you want until 100 minutes later\n",
    "    \n",
    "    basis = td['close'].loc[idx]\n",
    "    max_price = basis   # Initially the max price is the basis - No Shorting to Start\n",
    "    min_price = basis - (basis*pct)\n",
    "    time_stop = idx + max_holdtime \n",
    "    time_counter = idx\n",
    "    \n",
    "    #print(f\"Basis: {basis}\")\n",
    "\n",
    "    for i, row in after_td.iterrows():\n",
    "        close = row['close']\n",
    "        #print(f\"Close: {close}, Max: {max_price}, Min: {min_price}, Counter: {time_counter-idx}\")\n",
    "        if close > max_price:\n",
    "            max_price = close\n",
    "            min_price = max_price - (max_price * pct)\n",
    "        elif close < min_price:\n",
    "            profit = (close - basis) / basis\n",
    "            return [i, profit]\n",
    "        \n",
    "        time_counter += 1\n",
    "        if time_counter > time_stop:\n",
    "            break\n",
    "\n",
    "    # If the loop ends without triggering stop loss, calculate the profit based on the last close\n",
    "    profit = (close - basis) / basis\n",
    "    return [i, profit]\n",
    "            \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "print(TradingDay_df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "columns = []\n",
    "flattened_df100 = []\n",
    "columns100 = []\n",
    "flattened_df50 = []\n",
    "columns50 = []\n",
    "flattened_df20 = []\n",
    "columns20 = []\n",
    "flattened_df10 = []\n",
    "columns10 = []\n",
    "\n",
    "First_Index = TradingDay_df.index[0]\n",
    "Index_Counter = First_Index\n",
    "\n",
    "# Creating the CSV Files\n",
    "# 100\n",
    "packet = df[['open', 'close']].loc[First_Index-99:First_Index]\n",
    "for i in range(len(packet)):\n",
    "        columns100.append(f'open_{i+1}')\n",
    "        columns100.append(f'close_{i+1}')\n",
    "columns.append([\"EMA100\",\"EMA20\",\"RSI\",\"Profit\"])\n",
    "with open('packet100.csv', 'a', newline='') as f:\n",
    "      csv.writer(f).writerrow(columns)\n",
    "\n",
    "# 50\n",
    "packet = df[['open', 'close']].loc[First_Index-49:First_Index]\n",
    "for i in range(len(packet)):\n",
    "        columns100.append(f'open_{i+1}')\n",
    "        columns100.append(f'close_{i+1}')\n",
    "columns.append([\"EMA50\",\"EMA20\",\"RSI\",\"Profit\"])\n",
    "with open('packet50.csv', 'a', newline='') as f:\n",
    "      csv.writer(f).writerrow(columns)\n",
    "\n",
    "# 20\n",
    "packet = df[['open', 'close']].loc[First_Index-19:First_Index]\n",
    "for i in range(len(packet)):\n",
    "        columns100.append(f'open_{i+1}')\n",
    "        columns100.append(f'close_{i+1}')\n",
    "columns.append([\"EMA20\",\"EMA5\",\"RSI\",\"Profit\"])\n",
    "with open('packet20.csv', 'a', newline='') as f:\n",
    "      csv.writer(f).writerrow(columns)\n",
    "\n",
    "#10\n",
    "packet = df[['open', 'close']].loc[First_Index-9:First_Index]\n",
    "for i in range(len(packet)):\n",
    "        columns100.append(f'open_{i+1}')\n",
    "        columns100.append(f'close_{i+1}')\n",
    "columns.append([\"EMA10\",\"RSI\",\"Profit\"])\n",
    "with open('packet10.csv', 'a', newline='') as f:\n",
    "      csv.writer(f).writerrow(columns)\n",
    "\n",
    "\n",
    "\n",
    "for index, row in TradingDay_df.iterrows():\n",
    "\n",
    "    profit = trail_stoploss(index, df, 5)\n",
    "\n",
    "    # 100 Minutes\n",
    "    packet100 = df[['open', 'close']].loc[index-99:index]\n",
    "    flatpack100 = list(packet100.values.flatten())\n",
    "\n",
    "    packet100['EMA100'] = ta.ema(packet100['close'], length=100)\n",
    "    packet100['EMA20'] = ta.ema(packet100['close'], length=20)\n",
    "    packet100['RSI'] = ta.rsi(packet100['close'])\n",
    "\n",
    "    TA_100 = list(packet100[['EMA100','EMA20','RSI']].loc[index])\n",
    "    flatpack100.append(TA_100)\n",
    "    flatpack100.append(profit)\n",
    "    with open('packet100.csv', 'a', newline='') as f:\n",
    "      csv.writer(f).writerrow(flatpack100)\n",
    "\n",
    "    \n",
    "\n",
    "    # 50 Minutes\n",
    "    packet50 = df[['open', 'close']].loc[index-49:index]\n",
    "    flatpack50 = list(packet50.values.flatten())\n",
    "\n",
    "    # Trend Analysis\n",
    "    packet50['EMA50'] = ta.ema(packet50['close'], length=50)\n",
    "    packet50['EMA20'] = ta.ema(packet50['close'], length=20)\n",
    "    packet50['RSI'] = ta.rsi(packet50['close'])\n",
    "\n",
    "    TA_50 = list(packet50[['EMA50','EMA20','RSI']].loc[index])\n",
    "    addtional_flat = TA_50.append(profit)\n",
    "    flatpack50.append(addtional_flat)\n",
    "    with open('packet50.csv', 'a', newline='') as f:\n",
    "      csv.writer(f).writerrow(flatpack50)\n",
    "\n",
    "\n",
    "    # 20 Minutes\n",
    "    packet20 = df[['open', 'close']].loc[index-19:index]\n",
    "    flatpack20 = list(packet100.values.flatten())\n",
    "\n",
    "    # Trend Analysis\n",
    "    packet20['EMA20'] = ta.ema(packet20['close'], length=20)\n",
    "    packet20['EMA5'] = ta.ema(packet20['close'], length=5)\n",
    "    packet20['RSI'] = ta.rsi(packet20['close'])\n",
    "\n",
    "    TA_20 = list(packet20[['EMA20','EMA5','RSI']].loc[index])\n",
    "    addtional_flat = TA_20.append(profit)\n",
    "    flatpack20.append(addtional_flat)\n",
    "    with open('packet20.csv', 'a', newline='') as f:\n",
    "      csv.writer(f).writerrow(flatpack20)\n",
    "\n",
    "\n",
    "    # 10 Minutes   \n",
    "\n",
    "    packet10 = df[['open', 'close']].loc[index-9:index]\n",
    "    flatpack10 = list(packet10.values.flatten())\n",
    "\n",
    "    for i in range(len(packet10)):\n",
    "        columns10.append(f'open_{i+1}')\n",
    "        columns10.append(f'close_{i+1}')\n",
    "\n",
    "    # Trend Analysis\n",
    "    packet10['EMA10'] = ta.ema(packet10['close'], length=10)\n",
    "    packet10['RSI'] = ta.rsi(packet10['close'])\n",
    "\n",
    "    TA_10 = list(packet10[['EMA10','RSI']].loc[index])\n",
    "    addtional_flat = TA_10.append(profit)\n",
    "    additional_columns = [\"EMA10\",\"RSI\",\"Profit\"]\n",
    "    flatpack10.append(addtional_flat)\n",
    "    columns10.append(additional_columns)\n",
    "\n",
    "    \n",
    "    break\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['EMA5'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m235\u001b[39m\n\u001b[1;32m----> 3\u001b[0m TA_20 \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(packet100[[\u001b[39m'\u001b[39;49m\u001b[39mEMA20\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mEMA5\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mRSI\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39mloc[index])\n",
      "File \u001b[1;32mc:\\Users\\rybot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\rybot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rybot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['EMA5'] not in index\""
     ]
    }
   ],
   "source": [
    "index = 235\n",
    "\n",
    "TA_20 = list(packet100[['EMA20','EMA5','RSI']].loc[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
