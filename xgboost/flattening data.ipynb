{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with just 2023 for my laptop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<duckdb.duckdb.DuckDBPyConnection object at 0x00000214951D0C30>\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "con = duckdb.connect(r\"C:\\Users\\rybot\\OneDrive\\Databases\\datadump.duckdb\")\n",
    "print(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Stocks',)]\n"
     ]
    }
   ],
   "source": [
    "tables = con.execute('PRAGMA show_tables;').fetchall()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Datetime        open        high         low       close  volume  \\\n",
      "0 2023-01-03 04:00:00  129.391006  130.113998  129.386002  130.110001  5381.0   \n",
      "1 2023-01-03 04:01:00  129.977005  130.283005  129.972000  130.209000  6072.0   \n",
      "2 2023-01-03 04:02:00  130.285004  130.352005  130.270004  130.279007  1053.0   \n",
      "3 2023-01-03 04:03:00  130.294998  130.401993  130.289993  130.388000  1754.0   \n",
      "4 2023-01-03 04:04:00  130.384003  130.570999  130.378998  130.567001  3766.0   \n",
      "\n",
      "  Stock  interval  \n",
      "0  AAPL       1.0  \n",
      "1  AAPL       1.0  \n",
      "2  AAPL       1.0  \n",
      "3  AAPL       1.0  \n",
      "4  AAPL       1.0  \n"
     ]
    }
   ],
   "source": [
    "qry_year = '''\n",
    "    SELECT * FROM Stocks\n",
    "    WHERE EXTRACT(YEAR FROM Datetime) = 2023 \n",
    "    AND Stock = 'AAPL' \n",
    "    AND Interval = 1\n",
    "'''\n",
    "\n",
    "qry = f'''\n",
    "    SELECT * FROM Stocks\n",
    "    WHERE Stock = {Stock} \n",
    "    AND Interval = 1\n",
    "'''\n",
    "\n",
    "df = con.execute(qry).fetchdf()\n",
    "# Sort the Data from oldest to newest\n",
    "df = df.sort_values(by='Datetime').reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creating and Flattening the Data for:\n",
    "#### Packet Size (Only 1 min intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data, and calculating P/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 104714 entries, 235 to 220254\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count   Dtype         \n",
      "---  ------    --------------   -----         \n",
      " 0   Datetime  104714 non-null  datetime64[us]\n",
      " 1   open      104714 non-null  float32       \n",
      " 2   high      104714 non-null  float32       \n",
      " 3   low       104714 non-null  float32       \n",
      " 4   close     104714 non-null  float32       \n",
      " 5   volume    104714 non-null  float32       \n",
      " 6   Stock     104714 non-null  object        \n",
      " 7   interval  104714 non-null  float32       \n",
      " 8   Time      104714 non-null  object        \n",
      "dtypes: datetime64[us](1), float32(6), object(2)\n",
      "memory usage: 5.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df['Time'] = df['Datetime'].dt.time\n",
    "start_time = pd.to_datetime('09:00:00').time()\n",
    "end_time = pd.to_datetime('16:00:00').time()\n",
    "TradingDay_df = df[(df['Time']>start_time)&(df['Time']<end_time)]\n",
    "print(TradingDay_df.info())\n",
    "\n",
    "def trail_stoploss(index, tradingdata, whole_percentage):\n",
    "    idx = index\n",
    "    td = tradingdata\n",
    "    pct = whole_percentage/100\n",
    "    max_holdtime = 30 # Only hold the trade for twenty minutes\n",
    "\n",
    "    after_td = td.loc[idx:idx+max_holdtime+1] # Get the dataframe from the row you want until 100 minutes later\n",
    "    \n",
    "    basis = td['close'].loc[idx]\n",
    "    max_price = basis   # Initially the max price is the basis - No Shorting to Start\n",
    "    min_price = basis - (basis*pct)\n",
    "    time_stop = idx + max_holdtime \n",
    "    time_counter = idx\n",
    "    \n",
    "    #print(f\"Basis: {basis}\")\n",
    "\n",
    "    for i, row in after_td.iterrows():\n",
    "        close = row['close']\n",
    "        #print(f\"Close: {close}, Max: {max_price}, Min: {min_price}, Counter: {time_counter-idx}\")\n",
    "        if close > max_price:\n",
    "            max_price = close\n",
    "            min_price = max_price - (max_price * pct)\n",
    "        elif close < min_price:\n",
    "            profit = (close - basis) / basis\n",
    "            return [i, profit]\n",
    "        \n",
    "        time_counter += 1\n",
    "        if time_counter > time_stop:\n",
    "            break\n",
    "\n",
    "    # If the loop ends without triggering stop loss, calculate the profit based on the last close\n",
    "    profit = (close - basis) / basis\n",
    "    return [i, profit]\n",
    "            \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "print(TradingDay_df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "columns = []\n",
    "flattened_df100 = []\n",
    "columns100 = []\n",
    "\n",
    "First_Index = TradingDay_df.index[0]\n",
    "Index_Counter = First_Index\n",
    "\n",
    "# Creating the CSV Files\n",
    "# 100\n",
    "packet = df[['open', 'close']].loc[First_Index-99:First_Index]\n",
    "for i in range(len(packet)):\n",
    "        columns100.append(f'open_{i+1}')\n",
    "        columns100.append(f'close_{i+1}')\n",
    "columns100.extend([\"EMA100\",\"EMA20\",\"RSI\",\"Profit\",\"Index\",\"Profit Index\"])\n",
    "with open('packet100.csv', 'a', newline='') as f:\n",
    "      csv.writer(f).writerow(columns100)\n",
    "\n",
    "\n",
    "for index, row in TradingDay_df.iterrows():\n",
    "    \n",
    "    if index % 5000 ==0:\n",
    "         print(index)\n",
    "\n",
    "    trail_stop= trail_stoploss(index, df, 5)\n",
    "    profit = trail_stop[1]\n",
    "    profit_index = trail_stop[0]\n",
    "    \n",
    "\n",
    "    # 100 Minutes\n",
    "    packet100 = df[['open', 'close']].loc[index-99:index]\n",
    "    flatpack100 = list(packet100.values.flatten())\n",
    "\n",
    "    packet100['EMA100'] = ta.ema(packet100['close'], length=100)\n",
    "    packet100['EMA20'] = ta.ema(packet100['close'], length=20)\n",
    "    packet100['RSI'] = ta.rsi(packet100['close'])\n",
    "\n",
    "    TA_100 = list(packet100[['EMA100','EMA20','RSI']].loc[index])\n",
    "    flatpack100.extend(TA_100)\n",
    "    flatpack100.extend([profit,index,profit_index])\n",
    "    with open('packet100.csv', 'a', newline='') as f:\n",
    "      csv.writer(f).writerow(flatpack100)\n",
    "\n",
    " \n",
    "con.close() \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Whole Dataset for every Stock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JNJ', 'GS', 'AMD', 'BAC', 'WMT', 'BA', 'KO', 'WST', 'SPY', 'NVDA', 'GE', 'AAPL', 'XOM', 'MCD', 'AMZN', 'PG']\n"
     ]
    }
   ],
   "source": [
    "con = duckdb.connect(r\"C:\\Users\\rybot\\OneDrive\\Databases\\datadump.duckdb\")\n",
    "\n",
    "qry = f'''\n",
    "    SELECT DISTINCT(Stock) FROM Stocks\n",
    "'''\n",
    "\n",
    "df = con.execute(qry).fetchdf()\n",
    "# Sort the Data from oldest to newest\n",
    "print(list(df['Stock']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trail_stoploss(index, tradingdata, whole_percentage):\n",
    "    idx = index\n",
    "    td = tradingdata\n",
    "    pct = whole_percentage/100\n",
    "    max_holdtime = 30 # Only hold the trade for twenty minutes\n",
    "\n",
    "    after_td = td.loc[idx:idx+max_holdtime+1] # Get the dataframe from the row you want until 100 minutes later\n",
    "    \n",
    "    basis = td['close'].loc[idx]\n",
    "    max_price = basis   # Initially the max price is the basis - No Shorting to Start\n",
    "    min_price = basis - (basis*pct)\n",
    "    time_stop = idx + max_holdtime \n",
    "    time_counter = idx\n",
    "    \n",
    "    #print(f\"Basis: {basis}\")\n",
    "\n",
    "    for i, row in after_td.iterrows():\n",
    "        close = row['close']\n",
    "        #print(f\"Close: {close}, Max: {max_price}, Min: {min_price}, Counter: {time_counter-idx}\")\n",
    "        if close > max_price:\n",
    "            max_price = close\n",
    "            min_price = max_price - (max_price * pct)\n",
    "        elif close < min_price:\n",
    "            profit = (close - basis) / basis\n",
    "            return [i, profit]\n",
    "        \n",
    "        time_counter += 1\n",
    "        if time_counter > time_stop:\n",
    "            break\n",
    "\n",
    "    # If the loop ends without triggering stop loss, calculate the profit based on the last close\n",
    "    profit = (close - basis) / basis\n",
    "    return [i, profit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "45000\n",
      "50000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "125000\n",
      "130000\n",
      "145000\n",
      "160000\n",
      "175000\n",
      "185000\n",
      "190000\n",
      "195000\n",
      "200000\n",
      "205000\n",
      "215000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "245000\n",
      "250000\n",
      "260000\n",
      "280000\n",
      "305000\n",
      "315000\n",
      "320000\n",
      "330000\n",
      "335000\n",
      "340000\n",
      "345000\n",
      "355000\n",
      "360000\n",
      "365000\n",
      "370000\n",
      "375000\n",
      "380000\n",
      "385000\n",
      "390000\n",
      "395000\n",
      "400000\n",
      "405000\n",
      "410000\n",
      "415000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "475000\n",
      "480000\n",
      "485000\n",
      "495000\n",
      "505000\n",
      "510000\n",
      "515000\n",
      "525000\n",
      "530000\n",
      "535000\n",
      "540000\n",
      "545000\n",
      "550000\n",
      "555000\n",
      "560000\n",
      "565000\n",
      "570000\n",
      "575000\n",
      "580000\n",
      "585000\n",
      "590000\n",
      "595000\n",
      "630000\n",
      "635000\n",
      "645000\n",
      "650000\n",
      "655000\n",
      "660000\n",
      "665000\n",
      "670000\n",
      "675000\n",
      "685000\n",
      "690000\n",
      "695000\n",
      "700000\n",
      "705000\n",
      "715000\n",
      "720000\n",
      "730000\n",
      "750000\n",
      "755000\n",
      "760000\n",
      "765000\n",
      "775000\n",
      "785000\n",
      "795000\n",
      "800000\n",
      "805000\n",
      "810000\n",
      "815000\n",
      "830000\n",
      "835000\n",
      "840000\n",
      "850000\n",
      "855000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "885000\n",
      "895000\n",
      "925000\n",
      "930000\n",
      "940000\n",
      "945000\n",
      "955000\n",
      "960000\n",
      "965000\n",
      "970000\n",
      "990000\n",
      "995000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1045000\n",
      "1055000\n",
      "1065000\n",
      "1070000\n",
      "1075000\n",
      "1080000\n",
      "1085000\n",
      "1090000\n",
      "1110000\n",
      "1115000\n",
      "1120000\n",
      "1125000\n",
      "1130000\n",
      "1135000\n",
      "1140000\n",
      "1145000\n",
      "1150000\n",
      "1155000\n",
      "1160000\n",
      "1165000\n",
      "1180000\n",
      "1185000\n",
      "1190000\n",
      "1195000\n",
      "1200000\n",
      "1205000\n",
      "1215000\n",
      "1220000\n",
      "1230000\n",
      "1235000\n",
      "1240000\n",
      "1250000\n",
      "1255000\n",
      "1270000\n",
      "1290000\n",
      "1295000\n",
      "1300000\n",
      "1305000\n",
      "1310000\n",
      "1315000\n",
      "1325000\n",
      "1345000\n",
      "1355000\n",
      "1360000\n",
      "1365000\n",
      "1370000\n",
      "1375000\n",
      "1380000\n",
      "1385000\n",
      "1395000\n",
      "1400000\n",
      "1405000\n",
      "1410000\n",
      "1420000\n",
      "1435000\n",
      "1455000\n",
      "1460000\n",
      "1465000\n",
      "1470000\n",
      "1475000\n",
      "1495000\n",
      "1505000\n",
      "1510000\n",
      "1515000\n",
      "1520000\n",
      "1525000\n",
      "1550000\n",
      "1555000\n",
      "1570000\n",
      "1580000\n",
      "1585000\n",
      "1600000\n",
      "1610000\n",
      "1625000\n",
      "1640000\n",
      "1645000\n",
      "1665000\n",
      "1670000\n",
      "1680000\n",
      "1690000\n",
      "1705000\n",
      "1710000\n",
      "1715000\n",
      "1725000\n",
      "1730000\n",
      "1735000\n",
      "1750000\n",
      "1760000\n",
      "1770000\n",
      "1780000\n",
      "1800000\n",
      "1820000\n",
      "1825000\n",
      "1830000\n",
      "1835000\n",
      "1840000\n",
      "1850000\n",
      "1860000\n",
      "1870000\n",
      "1895000\n",
      "1900000\n",
      "1910000\n",
      "1935000\n",
      "1940000\n",
      "1945000\n",
      "1950000\n",
      "1970000\n",
      "1975000\n",
      "1990000\n",
      "2005000\n",
      "2010000\n",
      "2015000\n",
      "2020000\n",
      "2025000\n",
      "2030000\n",
      "2045000\n",
      "2050000\n",
      "2060000\n",
      "2080000\n",
      "2085000\n",
      "2090000\n",
      "2095000\n",
      "2110000\n",
      "2115000\n",
      "2120000\n",
      "2130000\n",
      "2135000\n",
      "2145000\n",
      "2150000\n",
      "2195000\n",
      "2205000\n",
      "2215000\n",
      "2220000\n",
      "2235000\n",
      "2240000\n",
      "2245000\n",
      "2255000\n",
      "2265000\n",
      "2275000\n",
      "2285000\n",
      "2310000\n",
      "2315000\n",
      "2330000\n",
      "2335000\n",
      "2350000\n",
      "2355000\n",
      "2375000\n",
      "2380000\n",
      "2395000\n",
      "2400000\n",
      "2415000\n",
      "2420000\n",
      "2430000\n",
      "2435000\n",
      "2455000\n",
      "2460000\n",
      "2475000\n",
      "2480000\n",
      "2500000\n",
      "2505000\n",
      "2520000\n",
      "2525000\n",
      "2545000\n",
      "2550000\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# ['JNJ', 'GS', 'AMD', 'BAC', 'WMT', 'BA', 'KO', 'WST', 'SPY', 'NVDA', 'GE', 'AAPL', 'XOM', 'MCD', 'AMZN', 'PG']\n",
    "\n",
    "con = duckdb.connect(r\"C:\\Users\\rybot\\OneDrive\\Databases\\datadump.duckdb\")\n",
    "Stocks = ['AAPL']\n",
    "\n",
    "for Stock in Stocks:\n",
    "    print(Stock)\n",
    "\n",
    "    qry = f'''\n",
    "        SELECT * FROM Stocks\n",
    "        WHERE Stock = '{Stock}' \n",
    "        AND Interval = 1\n",
    "    '''\n",
    "\n",
    "    df = con.execute(qry).fetchdf()\n",
    "    # Sort the Data from oldest to newest\n",
    "    df = df.sort_values(by='Datetime').reset_index(drop=True)\n",
    "\n",
    "    df['Time'] = df['Datetime'].dt.time\n",
    "    start_time = pd.to_datetime('09:00:00').time()\n",
    "    end_time = pd.to_datetime('16:00:00').time()\n",
    "    TradingDay_df = df[(df['Time'] > start_time) & (df['Time'] < end_time) & (df.index >= 101)]\n",
    "\n",
    "\n",
    "    columns = []\n",
    "    flattened_df100 = []\n",
    "    columns100 = []\n",
    "\n",
    "    First_Index = TradingDay_df.index[0]\n",
    "    Index_Counter = First_Index\n",
    "\n",
    "\n",
    "        # Creating the CSV Files\n",
    "        \n",
    "    packet = df[['open', 'close']].loc[First_Index-99:First_Index]\n",
    "    for i in range(len(packet)):\n",
    "            columns100.append(f'open_{i+1}')\n",
    "            columns100.append(f'close_{i+1}')\n",
    "    columns100.extend([\"EMA100\",\"EMA20\",\"RSI\",\"Profit\",\"Index\",\"Profit Index\"])\n",
    "    with open(f\"C:/Users/rybot/OneDrive/Databases/New100Packets/{Stock}_data.csv\", 'a', newline='') as f:\n",
    "        csv.writer(f).writerow(columns100)\n",
    "\n",
    "\n",
    "    for index, row in TradingDay_df.iterrows():\n",
    "        if index % 5000 ==0:\n",
    "            print(index)\n",
    "\n",
    "        trail_stop= trail_stoploss(index, df, 5)\n",
    "        profit = trail_stop[1]\n",
    "        profit_index = trail_stop[0]\n",
    "        \n",
    "\n",
    "        # 100 Minutes\n",
    "        packet100 = df[['open', 'close']].loc[index-99:index]\n",
    "        flatpack100 = list(packet100.values.flatten())\n",
    "\n",
    "        packet100['EMA100'] = ta.ema(packet100['close'], length=100)\n",
    "        packet100['EMA20'] = ta.ema(packet100['close'], length=20)\n",
    "        packet100['RSI'] = ta.rsi(packet100['close'])\n",
    "\n",
    "        TA_100 = list(packet100[['EMA100','EMA20','RSI']].loc[index])\n",
    "        flatpack100.extend(TA_100)\n",
    "        flatpack100.extend([profit,index,profit_index])\n",
    "        with open(f\"C:/Users/rybot/OneDrive/Databases/New100Packets/{Stock}_data.csv\", 'a', newline='') as f:\n",
    "            csv.writer(f).writerow(flatpack100)\n",
    "\n",
    "con.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt two of making money. Using change in close rather than open close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
